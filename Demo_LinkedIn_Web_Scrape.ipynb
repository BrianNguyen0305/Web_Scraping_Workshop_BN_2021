{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Demo_LinkedIn_Web_Scrape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianNguyen0305/Web_Scraping_Workshop_BN_2021/blob/main/Demo_LinkedIn_Web_Scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBO2XMG7jdv"
      },
      "source": [
        "# install packages\n",
        "import selenium as se \n",
        "import csv\n",
        "from time import sleep\n",
        "import xlrd\n",
        "import pandas as pd\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from parsel import Selector\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLsIZoYp7jdy"
      },
      "source": [
        "# defining new variable passing two parameters\n",
        "writer = csv.writer(open('Spring 2019 Grad Placement_6.csv', 'w+', encoding = 'utf-8-sig', newline = ''))\n",
        "\n",
        "# writerow() method to the write to the file object\n",
        "writer.writerow(['Name', 'Company', 'Title', 'Start_time', 'URL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LcVt1F7jdz"
      },
      "source": [
        "# writerow() method to the write to the file object\n",
        "writer.writerow(['Name', 'Company', 'Title', 'Start_time', 'URL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xHzCPt4e7jd0"
      },
      "source": [
        "# import web driver\n",
        "from selenium import webdriver\n",
        "\n",
        "# driver.get method() will navigate to a page given by the URL address\n",
        "driver.get('https://www.linkedin.com')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG-6p6gB7jd0"
      },
      "source": [
        "# locate email form by_class_name\n",
        "username = driver.find_element_by_name('session_key')\n",
        "\n",
        "# send_keys() to simulate key strokes\n",
        "username.send_keys('angelicatiger123@gmail.com')\n",
        "sleep(0.5)\n",
        "\n",
        "# locate password form by_class_name\n",
        "password = driver.find_element_by_name('session_password')\n",
        "\n",
        "# send_keys() to simulate key strokes\n",
        "password.send_keys(\"73Z9,XWG@:tscJT'\")\n",
        "sleep(0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk3t4ov97jd1"
      },
      "source": [
        "# locate submit button by_class_name\n",
        "log_in_button = driver.find_element_by_class_name(\"sign-in-form__submit-button\")\n",
        "\n",
        "# .click() to mimic button click\n",
        "log_in_button.click()\n",
        "sleep(0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zcnQL62R7jd1"
      },
      "source": [
        "#import names data:\n",
        "data = pd.read_excel('/content/drive/MyDrive/Web_Scraping_Workshop/Spring 2019 Grads Data.xlsx')\n",
        "names = data[\"FULL_NAME\"]\n",
        "feed_list = []\n",
        "\n",
        "# print('\"site:linkedin.com/in/', 'AND', '\"',i,'\"', 'AND \"Business Analytics\"', 'AND \"University of Texas at Dallas\"\",')\n",
        "#search term \n",
        "for i in names:\n",
        "    a = \"site:linkedin.com/in/\"\n",
        "    b = \"AND\"\n",
        "    c = i\n",
        "    d = \"AND\"\n",
        "    e = '\"Business Analytics\"'\n",
        "    s = \" \"\n",
        "    f = '\"Dallas\"'\n",
        "    result = a + s + c + s + e + s + f \n",
        "    feed_list.append(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-wKgfPst7jd2"
      },
      "source": [
        "# check if we made all search term for each names\n",
        "print(len(feed_list))\n",
        "\n",
        "print(feed_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "F8e9Ejzb7jd2"
      },
      "source": [
        "feed_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD6UR_IU7jd2"
      },
      "source": [
        "len(feed_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtjZmGWh7jd3"
      },
      "source": [
        "driver.get('https:www.google.com')\n",
        "sleep(3)\n",
        "\n",
        "search_query = driver.find_element_by_name('q')\n",
        "search_query.send_keys(feed_list[2])\n",
        "sleep(0.5)\n",
        "\n",
        "search_query.send_keys(Keys.RETURN)\n",
        "sleep(3)\n",
        "\n",
        "linkedin_urls = driver.find_elements_by_tag_name('a')\n",
        "linkedin_urls = [url.get_attribute('href') for url in linkedin_urls]\n",
        "linkedin_urls[31]\n",
        "sleep(0.5)\n",
        "    \n",
        "# use the first - best fit - search \n",
        "driver.get(linkedin_urls[31])\n",
        "\n",
        "# add a 5 second pause loading each URL\n",
        "sleep(5)\n",
        "\n",
        "# assigning the source code for the webpage to variable sel\n",
        "sel = Selector(text=driver.page_source)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRifMxFT7jd3"
      },
      "source": [
        "# xpath to extract the text from the class containing the name\n",
        "name = sel.xpath('//*[starts-with(@class, \"inline t-24 t-black t-normal break-words\")]/text()').extract_first()\n",
        "if name:\n",
        "    name = name.strip()\n",
        "\n",
        "# xpath to extract the text from the class containing the company name\n",
        "company = sel.xpath('//*[starts-with(@class, \"pv-entity__secondary-title t-14 t-black t-normal\")]/text()').extract_first()\n",
        "if company:\n",
        "    company = company.strip()\n",
        "\n",
        "# xpath to extract the text from the class containing the title\n",
        "title = sel.xpath('//*[starts-with(@class, \"t-16 t-black t-bold\")]/text()').extract_first()\n",
        "if title:\n",
        "    title = title.strip()\n",
        "\n",
        "    \n",
        "# xpath to extract the text from the class containing the time\n",
        "time = sel.xpath('//*[starts-with(@class, \"pv-entity__date-range t-14 t-black--light t-normal\")]/span[2]').extract_first()\n",
        "if time:\n",
        "    time = time.strip(\"<span>\")\n",
        "    time = time.strip(\"</\")\n",
        "    \n",
        "#url\n",
        "linkedin_url = driver.current_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKI6rgx67jd4"
      },
      "source": [
        "writer.writerow([name,\n",
        "                 company,\n",
        "                 title,\n",
        "                 time,\n",
        "                 linkedin_url])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mTqsgG5X7jd4"
      },
      "source": [
        "for x in feed_list[110:304]:\n",
        "    driver.get('https:www.google.com')\n",
        "    sleep(3)\n",
        "\n",
        "    search_query = driver.find_element_by_name('q')\n",
        "    search_query.send_keys(x)\n",
        "    sleep(0.5)\n",
        "\n",
        "    search_query.send_keys(Keys.RETURN)\n",
        "    sleep(3)\n",
        "\n",
        "    linkedin_urls = driver.find_elements_by_tag_name('a')\n",
        "    linkedin_urls = [url.get_attribute('href') for url in linkedin_urls]\n",
        "    linkedin_urls[31]\n",
        "    sleep(0.5)\n",
        "    \n",
        "    # use the first - best fit - search \n",
        "    driver.get(linkedin_urls[31])\n",
        "\n",
        "    # add a 5 second pause loading each URL\n",
        "    sleep(5)\n",
        "\n",
        "    # assigning the source code for the webpage to variable sel\n",
        "    sel = Selector(text=driver.page_source)\n",
        "\n",
        "    # xpath to extract the text from the class containing the name\n",
        "    name = sel.xpath('//*[starts-with(@class, \"inline t-24 t-black t-normal break-words\")]/text()').extract_first()\n",
        "    if name:\n",
        "        name = name.strip()\n",
        "\n",
        "    # xpath to extract the text from the class containing the company name\n",
        "    company = sel.xpath('//*[starts-with(@class, \"pv-entity__secondary-title t-14 t-black t-normal\")]/text()').extract_first()\n",
        "    if company:\n",
        "        company = company.strip()\n",
        "\n",
        "    # xpath to extract the text from the class containing the title\n",
        "    title = sel.xpath('//*[starts-with(@class, \"t-16 t-black t-bold\")]/text()').extract_first()\n",
        "    if title:\n",
        "        title = title.strip()\n",
        "\n",
        "\n",
        "    # xpath to extract the text from the class containing the time\n",
        "    time = sel.xpath('//*[starts-with(@class, \"pv-entity__date-range t-14 t-black--light t-normal\")]/span[2]').extract_first()\n",
        "    if time:\n",
        "        time = time.strip(\"<span>\")\n",
        "        time = time.strip(\"</\")\n",
        "\n",
        "    #url\n",
        "    linkedin_url = driver.current_url\n",
        "\n",
        "    # use the first - best fit - search \n",
        "    driver.get(linkedin_urls[31])\n",
        "\n",
        "    # add a 5 second pause loading each URL\n",
        "    sleep(5)\n",
        "\n",
        "    # assigning the source code for the webpage to variable sel\n",
        "    sel = Selector(text=driver.page_source)\n",
        "\n",
        "    #output to csv\n",
        "    writer.writerow([name,\n",
        "                     company,\n",
        "                     title,\n",
        "                     time,\n",
        "                     linkedin_url])\n",
        "    \n",
        "    print (\"----------------------------------\")\n",
        "    print (name)\n",
        "    print (company)\n",
        "    print (title)\n",
        "    print (time)\n",
        "    print (linkedin_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}